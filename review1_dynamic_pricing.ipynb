{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c93aba3",
   "metadata": {},
   "source": [
    "# Dynamic Pricing in E-Commerce — Review 1\n",
    "### Dataset: Brazilian Olist E-Commerce (2016–2018)\n",
    "### Algorithms: Linear Regression | Decision Tree\n",
    "\n",
    "**Objective:** Predict optimal product prices using historical order data to enable dynamic pricing strategies.\n",
    "\n",
    "| Step | Description |\n",
    "|---|---|\n",
    "| 1 | Load & merge all 8 datasets |\n",
    "| 2 | Exploratory Data Analysis (EDA) |\n",
    "| 3 | Feature Engineering |\n",
    "| 4 | Algorithm 1 — Linear Regression |\n",
    "| 5 | Algorithm 2 — Decision Tree |\n",
    "| 6 | Model Comparison |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947e6794",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c6b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6144b028",
   "metadata": {},
   "source": [
    "## Step 2: Load & Merge Datasets\n",
    "All 8 Olist CSV files are merged into one master dataframe on `order_id` and `product_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4aa904",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"d:\\SEM4\\F2 AI\\AI project\\project\"\n",
    "\n",
    "# Load all CSVs\n",
    "orders      = pd.read_csv(os.path.join(DATA_PATH, \"olist_orders_dataset.csv\"))\n",
    "items       = pd.read_csv(os.path.join(DATA_PATH, \"olist_order_items_dataset.csv\"))\n",
    "payments    = pd.read_csv(os.path.join(DATA_PATH, \"olist_order_payments_dataset.csv\"))\n",
    "reviews     = pd.read_csv(os.path.join(DATA_PATH, \"olist_order_reviews_dataset.csv\"))\n",
    "products    = pd.read_csv(os.path.join(DATA_PATH, \"olist_products_dataset.csv\"))\n",
    "customers   = pd.read_csv(os.path.join(DATA_PATH, \"olist_customers_dataset.csv\"))\n",
    "sellers     = pd.read_csv(os.path.join(DATA_PATH, \"olist_sellers_dataset.csv\"))\n",
    "translation = pd.read_csv(os.path.join(DATA_PATH, \"product_category_name_translation.csv\"))\n",
    "\n",
    "# Parse timestamps\n",
    "orders[\"order_purchase_timestamp\"]        = pd.to_datetime(orders[\"order_purchase_timestamp\"],        errors=\"coerce\")\n",
    "orders[\"order_delivered_customer_date\"]   = pd.to_datetime(orders[\"order_delivered_customer_date\"],   errors=\"coerce\")\n",
    "orders[\"order_estimated_delivery_date\"]   = pd.to_datetime(orders[\"order_estimated_delivery_date\"],   errors=\"coerce\")\n",
    "\n",
    "# Aggregate payments per order\n",
    "pay_agg = payments.groupby(\"order_id\").agg(\n",
    "    total_payment        = (\"payment_value\",        \"sum\"),\n",
    "    payment_installments = (\"payment_installments\", \"max\"),\n",
    "    payment_type         = (\"payment_type\",         lambda x: x.mode()[0])\n",
    ").reset_index()\n",
    "\n",
    "# Aggregate reviews per order\n",
    "rev_agg = reviews.groupby(\"order_id\").agg(\n",
    "    review_score = (\"review_score\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "# Translate product categories\n",
    "products = products.merge(translation, on=\"product_category_name\", how=\"left\")\n",
    "products[\"category_en\"] = products[\"product_category_name_english\"].fillna(\"Other\")\n",
    "\n",
    "# Build master dataframe\n",
    "master = (items\n",
    "    .merge(orders,    on=\"order_id\",   how=\"left\")\n",
    "    .merge(pay_agg,   on=\"order_id\",   how=\"left\")\n",
    "    .merge(rev_agg,   on=\"order_id\",   how=\"left\")\n",
    "    .merge(products,  on=\"product_id\", how=\"left\")\n",
    "    .merge(customers, on=\"customer_id\",how=\"left\")\n",
    "    .merge(sellers,   on=\"seller_id\",  how=\"left\")\n",
    ")\n",
    "\n",
    "# Keep only delivered orders with valid prices\n",
    "master = master[\n",
    "    (master[\"order_status\"] == \"delivered\") &\n",
    "    (master[\"price\"] > 0) & (master[\"price\"] < 5000)\n",
    "].copy()\n",
    "\n",
    "# Date features\n",
    "master[\"purchase_month\"]  = master[\"order_purchase_timestamp\"].dt.month\n",
    "master[\"purchase_dow\"]    = master[\"order_purchase_timestamp\"].dt.dayofweek\n",
    "master[\"purchase_year\"]   = master[\"order_purchase_timestamp\"].dt.year\n",
    "master[\"is_weekend\"]      = master[\"purchase_dow\"].isin([5, 6]).astype(int)\n",
    "\n",
    "# Delivery features\n",
    "master[\"days_to_deliver\"] = (master[\"order_delivered_customer_date\"] -\n",
    "                              master[\"order_purchase_timestamp\"]).dt.days\n",
    "master[\"delivery_delay\"]  = (master[\"order_delivered_customer_date\"] -\n",
    "                              master[\"order_estimated_delivery_date\"]).dt.days.fillna(0)\n",
    "\n",
    "# Price features\n",
    "master[\"freight_ratio\"]   = master[\"freight_value\"] / (master[\"price\"] + 1e-3)\n",
    "\n",
    "print(f\"Master dataset: {master.shape[0]:,} rows × {master.shape[1]} columns\")\n",
    "print(f\"Date range    : {master['order_purchase_timestamp'].min().date()} → {master['order_purchase_timestamp'].max().date()}\")\n",
    "print(f\"Categories    : {master['category_en'].nunique()}\")\n",
    "master[[\"price\", \"freight_value\", \"review_score\", \"payment_installments\", \"days_to_deliver\"]].describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f431a308",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d827b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# --- Plot 1: Price Distribution ---\n",
    "axes[0][0].hist(master[\"price\"].clip(0, 500), bins=50, color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[0][0].set_title(\"Price Distribution (clipped at R$500)\", fontweight=\"bold\")\n",
    "axes[0][0].set_xlabel(\"Price (R$)\")\n",
    "axes[0][0].set_ylabel(\"Count\")\n",
    "axes[0][0].axvline(master[\"price\"].median(), color=\"red\", linestyle=\"--\",\n",
    "                   label=f\"Median: R${master['price'].median():.0f}\")\n",
    "axes[0][0].legend()\n",
    "\n",
    "# --- Plot 2: Top 10 Categories by Order Volume ---\n",
    "top_cats = master[\"category_en\"].value_counts().head(10)\n",
    "axes[0][1].barh(top_cats.index[::-1], top_cats.values[::-1], color=\"steelblue\")\n",
    "axes[0][1].set_title(\"Top 10 Categories by Order Volume\", fontweight=\"bold\")\n",
    "axes[0][1].set_xlabel(\"Number of Orders\")\n",
    "\n",
    "# --- Plot 3: Avg Price per Top Category ---\n",
    "cat_price = master.groupby(\"category_en\")[\"price\"].mean().nlargest(10)\n",
    "axes[0][2].barh(cat_price.index[::-1], cat_price.values[::-1], color=\"tomato\")\n",
    "axes[0][2].set_title(\"Top 10 Categories by Avg Price\", fontweight=\"bold\")\n",
    "axes[0][2].set_xlabel(\"Avg Price (R$)\")\n",
    "\n",
    "# --- Plot 4: Review Score Distribution ---\n",
    "axes[1][0].hist(master[\"review_score\"].dropna(), bins=5, color=\"gold\", edgecolor=\"white\",\n",
    "                rwidth=0.8)\n",
    "axes[1][0].set_title(\"Review Score Distribution\", fontweight=\"bold\")\n",
    "axes[1][0].set_xlabel(\"Review Score (1–5)\")\n",
    "axes[1][0].set_ylabel(\"Count\")\n",
    "\n",
    "# --- Plot 5: Monthly Order Volume ---\n",
    "monthly_vol = master.groupby([\"purchase_year\", \"purchase_month\"])[\"order_id\"].count().reset_index()\n",
    "monthly_vol[\"period\"] = monthly_vol[\"purchase_year\"].astype(str) + \"-\" + \\\n",
    "                         monthly_vol[\"purchase_month\"].astype(str).str.zfill(2)\n",
    "monthly_vol = monthly_vol.sort_values(\"period\")\n",
    "axes[1][1].plot(monthly_vol[\"period\"], monthly_vol[\"order_id\"], \"o-\", color=\"steelblue\", linewidth=2)\n",
    "axes[1][1].set_title(\"Monthly Order Volume\", fontweight=\"bold\")\n",
    "axes[1][1].set_xlabel(\"Month\")\n",
    "axes[1][1].set_ylabel(\"Orders\")\n",
    "axes[1][1].tick_params(axis=\"x\", rotation=45, labelsize=7)\n",
    "\n",
    "# --- Plot 6: Price vs Review Score (box plot) ---\n",
    "master[\"review_bucket\"] = master[\"review_score\"].dropna().astype(int)\n",
    "bucket_data = [master[master[\"review_score\"].astype(\"Int64\") == s][\"price\"].clip(0, 500).dropna()\n",
    "               for s in range(1, 6)]\n",
    "axes[1][2].boxplot(bucket_data, labels=[\"1★\", \"2★\", \"3★\", \"4★\", \"5★\"],\n",
    "                   patch_artist=True,\n",
    "                   boxprops=dict(facecolor=\"lightblue\"),\n",
    "                   medianprops=dict(color=\"red\", linewidth=2))\n",
    "axes[1][2].set_title(\"Price Distribution by Review Score\", fontweight=\"bold\")\n",
    "axes[1][2].set_xlabel(\"Review Score\")\n",
    "axes[1][2].set_ylabel(\"Price (R$)\")\n",
    "\n",
    "plt.suptitle(\"Exploratory Data Analysis — Olist E-Commerce Dataset\", fontsize=14,\n",
    "             fontweight=\"bold\", y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "num_cols = [\"price\", \"freight_value\", \"review_score\", \"payment_installments\",\n",
    "            \"days_to_deliver\", \"freight_ratio\", \"purchase_month\", \"is_weekend\"]\n",
    "corr = master[num_cols].dropna().corr()\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(9, 7))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0,\n",
    "            linewidths=0.5, ax=ax2)\n",
    "ax2.set_title(\"Correlation Matrix of Numeric Features\", fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3de4e",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering\n",
    "\n",
    "We encode the categorical `category_en` feature and select a concise set of input features to predict `price`.\n",
    "\n",
    "| Feature | Description |\n",
    "|---|---|\n",
    "| `freight_value` | Shipping cost |\n",
    "| `review_score` | Customer rating (1–5) |\n",
    "| `payment_installments` | Number of payment instalments |\n",
    "| `days_to_deliver` | Actual delivery time in days |\n",
    "| `purchase_month` | Month of purchase (1–12) |\n",
    "| `is_weekend` | 1 if ordered on Sat/Sun |\n",
    "| `category_encoded` | Label-encoded product category |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ── Encode product category ──────────────────────────────────────────────────\n",
    "le = LabelEncoder()\n",
    "master[\"category_encoded\"] = le.fit_transform(master[\"category_en\"].fillna(\"unknown\"))\n",
    "\n",
    "# ── Select features and target ───────────────────────────────────────────────\n",
    "FEATURES = [\"freight_value\", \"review_score\", \"payment_installments\",\n",
    "            \"days_to_deliver\", \"purchase_month\", \"is_weekend\", \"category_encoded\"]\n",
    "TARGET = \"price\"\n",
    "\n",
    "df_model = master[FEATURES + [TARGET]].dropna()\n",
    "print(f\"Modelling dataset: {len(df_model):,} rows  |  {len(FEATURES)} features\")\n",
    "\n",
    "X = df_model[FEATURES]\n",
    "y = df_model[TARGET]\n",
    "\n",
    "# ── Train / test split (80 / 20) ─────────────────────────────────────────────\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "print(f\"Train size : {len(X_train):,}   |   Test size : {len(X_test):,}\")\n",
    "\n",
    "# ── Helper: evaluation metrics ───────────────────────────────────────────────\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import math\n",
    "\n",
    "def evaluate(model_name, y_true, y_pred):\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    print(f\"{model_name:30s}  RMSE={rmse:.2f}   MAE={mae:.2f}   R²={r2:.4f}\")\n",
    "    return {\"model\": model_name, \"RMSE\": rmse, \"MAE\": mae, \"R²\": r2}\n",
    "\n",
    "results = []   # collect both models here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0b650",
   "metadata": {},
   "source": [
    "## Step 5: Algorithm 1 — Linear Regression\n",
    "\n",
    "**Linear Regression** models the target as a weighted sum of input features:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n$$\n",
    "\n",
    "It is interpretable and acts as our **baseline** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ── Train ────────────────────────────────────────────────────────────────────\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# ── Predict & evaluate ───────────────────────────────────────────────────────\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_metrics = evaluate(\"Linear Regression\", y_test, lr_pred)\n",
    "results.append(lr_metrics)\n",
    "\n",
    "# ── Coefficient table ─────────────────────────────────────────────────────────\n",
    "coef_df = pd.DataFrame({\"Feature\": FEATURES, \"Coefficient\": lr_model.coef_})\n",
    "coef_df = coef_df.reindex(coef_df[\"Coefficient\"].abs().sort_values(ascending=False).index)\n",
    "print(\"\\nFeature Coefficients (sorted by |value|):\")\n",
    "print(coef_df.to_string(index=False))\n",
    "\n",
    "# ── Plots ─────────────────────────────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[0].scatter(y_test, lr_pred, alpha=0.3, s=10, color=\"steelblue\")\n",
    "lims = [0, min(y_test.max(), lr_pred.max(), 1500)]\n",
    "axes[0].plot(lims, lims, \"r--\", linewidth=2, label=\"Perfect fit\")\n",
    "axes[0].set_xlabel(\"Actual Price (R$)\")\n",
    "axes[0].set_ylabel(\"Predicted Price (R$)\")\n",
    "axes[0].set_title(\"Linear Regression — Actual vs Predicted\", fontweight=\"bold\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test - lr_pred\n",
    "axes[1].scatter(lr_pred, residuals, alpha=0.3, s=10, color=\"tomato\")\n",
    "axes[1].axhline(0, color=\"black\", linewidth=1.5)\n",
    "axes[1].set_xlabel(\"Predicted Price (R$)\")\n",
    "axes[1].set_ylabel(\"Residual\")\n",
    "axes[1].set_title(\"Linear Regression — Residual Plot\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd97482",
   "metadata": {},
   "source": [
    "## Step 6: Algorithm 2 — Decision Tree Regressor\n",
    "\n",
    "A **Decision Tree** recursively splits the feature space into regions and predicts the mean target value in each leaf. It can capture **non-linear** pricing patterns that Linear Regression misses.\n",
    "\n",
    "We limit `max_depth=5` to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d538ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "# ── Train ────────────────────────────────────────────────────────────────────\n",
    "dt_model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# ── Predict & evaluate ───────────────────────────────────────────────────────\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "dt_metrics = evaluate(\"Decision Tree (max_depth=5)\", y_test, dt_pred)\n",
    "results.append(dt_metrics)\n",
    "\n",
    "# ── Feature importance ────────────────────────────────────────────────────────\n",
    "imp_df = pd.DataFrame({\"Feature\": FEATURES, \"Importance\": dt_model.feature_importances_})\n",
    "imp_df = imp_df.sort_values(\"Importance\", ascending=False)\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(imp_df.to_string(index=False))\n",
    "\n",
    "# ── Plots ─────────────────────────────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[0].scatter(y_test, dt_pred, alpha=0.3, s=10, color=\"seagreen\")\n",
    "lims = [0, min(y_test.max(), dt_pred.max(), 1500)]\n",
    "axes[0].plot(lims, lims, \"r--\", linewidth=2, label=\"Perfect fit\")\n",
    "axes[0].set_xlabel(\"Actual Price (R$)\")\n",
    "axes[0].set_ylabel(\"Predicted Price (R$)\")\n",
    "axes[0].set_title(\"Decision Tree — Actual vs Predicted\", fontweight=\"bold\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Feature Importance bar chart\n",
    "axes[1].barh(imp_df[\"Feature\"][::-1], imp_df[\"Importance\"][::-1], color=\"seagreen\")\n",
    "axes[1].set_xlabel(\"Importance Score\")\n",
    "axes[1].set_title(\"Decision Tree — Feature Importances\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ── Tree structure visualisation (depth 3 for readability) ────────────────────\n",
    "fig3, ax3 = plt.subplots(figsize=(20, 8))\n",
    "plot_tree(dt_model, max_depth=3, feature_names=FEATURES, filled=True,\n",
    "          fontsize=8, rounded=True, precision=1, ax=ax3)\n",
    "ax3.set_title(\"Decision Tree Structure (top 3 levels)\", fontweight=\"bold\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7adfe0e",
   "metadata": {},
   "source": [
    "## Step 7: Model Comparison & Conclusion\n",
    "\n",
    "We compare both models on the same held-out test set using three metrics:\n",
    "\n",
    "| Metric | Meaning | Lower/Higher is better |\n",
    "|---|---|---|\n",
    "| **RMSE** | Root Mean Squared Error — penalises large errors | **Lower** |\n",
    "| **MAE** | Mean Absolute Error — average absolute deviation | **Lower** |\n",
    "| **R²** | Explained variance (0–1 scale) | **Higher** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b85340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ── Summary table ─────────────────────────────────────────────────────────────\n",
    "results_df = pd.DataFrame(results).set_index(\"model\")\n",
    "print(\"=\" * 55)\n",
    "print(\"          MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 55)\n",
    "print(results_df.to_string())\n",
    "print(\"=\" * 55)\n",
    "\n",
    "winner = results_df[\"RMSE\"].idxmin()\n",
    "improvement = (results_df.loc[results_df[\"RMSE\"].idxmax(), \"RMSE\"] -\n",
    "               results_df[\"RMSE\"].min()) / results_df[\"RMSE\"].max() * 100\n",
    "print(f\"\\nBest model by RMSE: {winner}\")\n",
    "print(f\"RMSE improvement  : {improvement:.1f}%\")\n",
    "\n",
    "# ── Bar chart: RMSE and MAE ───────────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "metrics_to_plot = [\"RMSE\", \"MAE\", \"R²\"]\n",
    "colors = [\"steelblue\", \"seagreen\"]\n",
    "model_labels = [r.replace(\" (max_depth=5)\", \"\") for r in results_df.index]\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    vals = results_df[metric].values\n",
    "    bars = axes[i].bar(model_labels, vals, color=colors, edgecolor=\"white\", width=0.5)\n",
    "    axes[i].set_title(f\"{metric} Comparison\", fontweight=\"bold\")\n",
    "    axes[i].set_ylabel(metric)\n",
    "    for bar, v in zip(bars, vals):\n",
    "        axes[i].text(bar.get_x() + bar.get_width() / 2,\n",
    "                     bar.get_height() + 0.01 * abs(v),\n",
    "                     f\"{v:.2f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    if metric == \"R²\":\n",
    "        axes[i].set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle(\"Model Comparison — Linear Regression vs Decision Tree\",\n",
    "             fontsize=13, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ── Side-by-side Actual vs Predicted ─────────────────────────────────────────\n",
    "fig2, axes2 = plt.subplots(1, 2, figsize=(14, 5))\n",
    "plot_data = [(\"Linear Regression\", lr_pred, \"steelblue\"),\n",
    "             (\"Decision Tree\",     dt_pred,  \"seagreen\")]\n",
    "\n",
    "for ax, (name, pred, col) in zip(axes2, plot_data):\n",
    "    ax.scatter(y_test.values[:500], pred[:500], alpha=0.4, s=12, color=col, label=name)\n",
    "    lim = min(float(y_test.max()), float(pred.max()), 1000)\n",
    "    ax.plot([0, lim], [0, lim], \"r--\", linewidth=2)\n",
    "    ax.set_xlabel(\"Actual Price (R$)\")\n",
    "    ax.set_ylabel(\"Predicted Price (R$)\")\n",
    "    ax.set_title(f\"{name} — Actual vs Predicted (first 500 test pts)\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Review 1 notebook complete.\")\n",
    "print(\"   Two baseline algorithms trained, evaluated, and compared.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
